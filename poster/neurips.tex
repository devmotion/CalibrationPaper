% arara: lualatex: { shell: true }
% arara: lualatex: { shell: true }
% arara: lualatex: { shell: true, synctex: true }

% A2  : 420 x 594 mm    |
% 2A0 : 1189 x 1682 mm  > Factor 2.83 => 11pt ~ 31 pt
% 1m  : 1000 x 1414     > Factor 2.38 => 12pt ~ 28 pt

% A3  : 297 x 420 mm    |
% 2A0 : 1189 x 1682 mm  > Factor 4 => 11pt ~ 44 pt
% 1m  : 1000 x 1414     > Factor 3.36 => 10pt ~ 34 pt
\documentclass[10pt]{article}

\usepackage{luatex85}

% layout
\usepackage[a3paper,landscape]{geometry}

% math support
\usepackage{mathtools,amssymb}

% fonts
\RequirePackage[factor=0]{microtype} % no protrusion
\usepackage{unicode-math}
\defaultfontfeatures{Ligatures=TeX}
\IfFileExists{fonts/Berling.otf}{%
  % load fonts of official UU design
  \setmainfont{Berling}[%
  Path=./fonts/,
  Extension=.otf,
  BoldFont=*-Bold,
  ItalicFont=*-Italic,
  BoldItalicFont=*-BoldItalic]
}{%
  \setmainfont{Libertinus Serif}
}
\setsansfont{Libertinus Sans}
\setmonofont{Libertinus Mono}
\setmathfont{Libertinus Math}

\usepackage{bm}

% language support
\usepackage{polyglossia}
\setdefaultlanguage{english}
\usepackage{csquotes}

% better looking tables
\usepackage{booktabs}

% colors
\usepackage[CMYK]{xcolor}
\usepackage{UUcolorPantone}

\newcommand{\hl}[1]{\begingroup\bfseries\boldmath\color{uured}#1\endgroup}

% graphics
\usepackage{graphics}

% captions
\usepackage{caption,subcaption}
\captionsetup{font=scriptsize}

% fancy lists
\usepackage{enumitem}
\setlist{leftmargin=*,itemsep=0pt}
\setlist[itemize,1]{label={\color{uured}$\blacktriangleright$}}

% hyperlinks
\usepackage{hyperref}

% boxes
\usepackage[poster,xparse]{tcolorbox}

% poster settings
\tcbposterset{
  coverage =
  {
    spread,
    interior style={color=white},
  },
  poster =
  {
    columns=5,
    rows=5,
    showframe=true, % useful for debugging
  },
  boxes =
  {
    enhanced standard jigsaw,
    sharp corners=downhill,
    arc=3pt,
    boxrule=1pt,
    lower separated=false,
    % colors
    coltext=black,
    colback=white,
    colframe=black,
    coltitle=black,
    colbacktitle=uulightgrey,
    % fonts
    fonttitle=\bfseries\large,
    % subtitles
    subtitle style=
    {
      frame empty,
      hbox,
      rounded corners=east,
      arc=8pt,
      coltext=white!50!uulightgrey,
      colback=black!10!uudarkgrey,
    },
  }
}

% plots
\usepackage{pgfplots,pgfplotstable}
\pgfplotsset{compat=1.16}

% general settings for plots
\pgfplotsset{grid style=dashed}
\pgfplotsset{enlargelimits=auto}

\usepgfplotslibrary{groupplots,colorbrewer}
\usetikzlibrary{plotmarks,calc}

% plotting options
\pgfplotsset{table/search path={data/}}
\pgfplotsset{max space between ticks=150}
\pgfplotsset{every axis/.append style={axis background style={fill=gray!10}},tick label style={font={\footnotesize}}, label style={font={\small}}}
\pgfplotsset{every axis plot/.append style={thick}}
\pgfplotsset{every axis legend/.append style={font=\small, fill=none}}

% automatic references
\usepackage{cleveref}

% some abbreviations
\newcommand{\Prob}{\mathbb{P}}
\newcommand*{\E}{\mathbb{E}}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator{\ECE}{ECE}
\DeclareMathOperator{\biasedskce}{SKCE_b}
\DeclareMathOperator{\unbiasedskce}{SKCE_{uq}}
\DeclareMathOperator{\linearskce}{SKCE_{ul}}
\DeclareMathOperator{\asympunbiasedskce}{aSKCE_{uq}}
\DeclareMathOperator{\asymplinearskce}{aSKCE_{ul}}
\DeclareMathOperator{\measure}{CE}
\DeclareMathOperator{\kernelmeasure}{KCE}
\DeclareMathOperator{\squaredkernelmeasure}{SKCE}
\DeclareMathOperator{\Expect}{\mathbb{E}}
\DeclareMathOperator{\Dir}{Dir}
\DeclareMathOperator{\Categorical}{Cat}

% metadata
\title{Calibration tests in multi-class classification:\\ A unifying framework}
\author{David Widmann$^\star$ Fredrik Lindsten$^\dagger$ Dave Zachariah$^\star$}
\date{\today}
\makeatletter
\pgfkeys{%
  /my poster/.cd,
  title/.initial=\@title,
  author/.initial=\@author,
  institute/.initial={},
  contact/.initial={},
  date/.initial=\@date,
}
\makeatother

\pgfkeys{%
  /my poster/.cd,
  institute={$^\star$Department of Information Technology, Uppsala University $^\ddagger$Division of Statistics and Machine Learning, Link√∂ping University},
  contact={david.widmann@it.uu.se fredrik.lindsten@liu.se dave.zachariah@it.uu.se},
}

\pagestyle{empty}

\begin{document}
\begin{tcbposter}

  % title
  \posterbox[blankest,interior engine=path,halign=left,valign=center,right=4cm,
  underlay =
  {%
    \node[left,inner sep=0pt,outer sep=0pt,align=center] at (frame.east) {\includegraphics[width=2cm]{figures/logos/UU.pdf}\\[1ex]\includegraphics[width=3cm]{figures/logos/LiU.pdf}};%
  }]{name=title,column=1,span=3,below=top}{%
    \Huge\textbf{\pgfkeysvalueof{/my poster/title}}\\[1ex]
    \large\pgfkeysvalueof{/my poster/author}\\[1ex]
    \normalsize\pgfkeysvalueof{/my poster/institute}%
  }%

  % footline
  \posterbox[blankest,top=2pt,bottom=2pt,valign=center,fontupper=\ttfamily\small,interior engine=path,interior style={color=uumidgrey}%
  ]{name=footline,column=1,span=5,above=bottom}{%
    \pgfkeysvalueof{/my poster/date}\hfill\pgfkeysvalueof{/my poster/contact}%
  }%

  \posterbox[adjusted title=The paper in 30 seconds, colback=blondmellan]{name=summary,column=1,below=title}{
    \begin{itemize}
    \item We propose a \hl{unifying framework} of calibration errors
      that allows us to derive a new \hl{kernel calibration error} with
      \hl{unbiased and consistent estimators}.
    \item Calibration error estimates are not interpretable. Instead we
      can conduct hypothesis tests of calibration.
    \item In contrast to existing approaches, the KCE enables
      well-founded bounds and approximations of the p-value for
      calibration tests.
    \end{itemize}

    \tcbsubtitle{Take with you}
    \begin{itemize}
    \item Kernel calibration error (KCE) with unbiased and consistent estimators
    \item Calibration errors have no meaningful unit or scale
    \item Reliable calibrations tests with the KCE
    \end{itemize}
  }

  \posterbox[adjusted title=General setup]{name=setup,column=1,below=summary}{
    \begin{itemize}
    \item Let $X$ be random inputs (features) of $m$ classes $1,\ldots,m$, denoted by $Y$.
    \item Consider a \hl{probabilistic model} $g$ that predicts a probability distribution of classes $g(X) \in \Delta^{m}$ for input $X$, where $\Delta^m \coloneqq \{z \in \mathbb{R}^m_{\geq 0} : \|z\|_1 = 1\}$ denotes the $(m-1)$-dimensional probability simplex.
    \item Ideally $g$ predicts $g_y(X) = \Prob[Y = y \,|\,X]$ for all classes $y$.
    \end{itemize}
  }

  \posterbox[adjusted title={Calibration}]{name=calibration,column=1,below=setup}{
    Although in practice the model will never be ideal but at most close to it, we can strive to satisfy other desirable statistical properties such as \hl{calibration}.
    \begin{tcolorbox}[colback=blondsvag, halign=center]
      Informally, in the long run every prediction should match the relative frequencies of the observed classes.
    \end{tcolorbox}
    Mathematically, a model \(g\) is calibrated if
    \begin{equation*}
      g_y(X) = \Prob[Y = y \,|\, g(X)] \quad \text{a.s.\ for all classes } y,
    \end{equation*}
    or equivalently if
    \begin{equation}\label{eq:calibration}
      \begin{split}
        g(X) &= r(g(X)) \\
        &\coloneqq (\mathbb{P}[Y = 1 \,|\, g(X)], \ldots, \mathbb{P}[Y = m \,|\, g(X)]) \quad \text{a.s.}.
      \end{split}
    \end{equation}
  }

  \posterbox[adjusted title={Calibration error}]{name=error,column=2,span=2,below=title}{
    We propose the following general measure of miscalibration which arises naturally from the definition of calibration in \cref{eq:calibration}.

    \begin{tcolorbox}[colback=sandstark]
      The \hl{calibration error}~($\measure$) of model $g$ w.r.t.\ a class $\mathcal{F}$ of functions $f \colon \Delta^m \to \mathbb{R}^m$ is
      \begin{equation*}
        \measure[\mathcal{F}, g] \coloneqq \sup_{f \in \mathcal{F}} \Expect\left[{(r(g(X)) - g(X))}^\intercal f(g(X)) \right].
      \end{equation*}
    \end{tcolorbox}

    \vspace{-\topsep}
    \begin{itemize}
    \item By design, if model $g$ is calibrated then the $\measure$ is zero, regardless of $\mathcal{F}$.
    \item The $\measure$ is equal to the common expected calibration error ($\ECE$)
      \begin{equation}\label{eq:ece}
        \ECE[d, g] = \Expect[d(r(g(X)), g(X))]
      \end{equation}
      for certain choices of $\mathcal{F}$ and distances $d$ such as the city block distance, the total variation distance, and the squared Euclidean distance.
    \item The $\measure$ captures also the maximum mean calibration error.
    \end{itemize}
  }

  \posterbox[adjusted title={Kernel calibration error}]{name=kce,column=2,span=2,below=error}{
    Let $\mathcal{F}$ be the unit ball in a reproducing kernel Hilbert space with matrix-valued kernel $k \colon \Delta^m \times \Delta^m \to \mathbb{R}^{m \times m}$. Then we define the \hl{kernel calibration error} ($\kernelmeasure$) with respect to kernel $k$ as $\kernelmeasure[k, g] \coloneqq \measure[\mathcal{F}, g]$.

    \begin{tcolorbox}[colback=blondsvag]
      An example of a matrix-valued kernel is $k(a, b) = M \tilde{k}(a, b)$, where $M \in \mathbb{R}^{m\times m}$ is a positive semi-definite matrix and $\tilde{k} \colon \Delta^m \times \Delta^m \to \mathbb{R}$ is a real-valued kernel.
    \end{tcolorbox}

    If $k$ is a universal kernel, then the $\kernelmeasure$ is zero if and only if model $g$ is calibrated.

    \begin{tcolorbox}[colback=sandstark]
      If $\Expect[\|k(g(X),g(X))\|] < \infty$, then
      \begin{equation}\label{eq:kce}
        \kernelmeasure[k,g] = {\bigg(\Expect[{(e_Y - g(X))}^{\intercal} k(g(X), g(X')) {(e_{Y'} - g(X'))}]\bigg)}^{1/2},
      \end{equation}
      where $(X', Y')$ is an independent copy of $(X,Y)$ and $e_i$ denotes the $i$th unit vector.
    \end{tcolorbox}
  }

  \posterbox[adjusted title={Viewing estimators as test statistics}]{name=statistics,column=2,span=2,between=kce and footline}{
    In general, the $\measure$ does not have a meaningful unit or scale. This renders it difficult to interpret an estimated non-zero error and to compare different models.

    \begin{tcolorbox}[colback=sandstark]
      For the consistent and unbiased estimators of the $\squaredkernelmeasure$ we derive \hl{bounds and approximations of the probability of false rejection} of a calibrated model.
    \end{tcolorbox}

    \vspace{-\topsep}
    \begin{itemize}
    \item These results allow us to test the hypothesis that model $g$ is calibrated.
    \item The bounds enable us to transfer unintuitive calibration error estimates to an \hl{intuitive and interpretable} probabilistic setting.
    \end{itemize}
  }

  \posterbox[adjusted title={Estimators of the calibration error}]{name=estimator,column=4,span=2,below=top}{
    Consider the task of estimating the $\measure$ of model $g$ using a validation set $\{(X_i, Y_i)\}_{i=1}^n$ of i.i.d.\ random pairs of inputs and labels that are distributed according to $(X,Y)$.

    \begin{itemize}
    \item Standard estimators of the $\ECE$ are inconsistent and biased in many cases and can scale poorly to large $m$.

      \begin{tcolorbox}[colback=blondsvag]
        The main difficulty is the estimation of the function $r$ in \cref{eq:ece}. \Cref{eq:kce} shows that for $\kernelmeasure$ there is no explicit dependence on $r$!
      \end{tcolorbox}

    \item For $i,j \in \{1,\ldots,n\}$ define $h_{i,j} \coloneqq {(e_{Y_i} - g(X_i))}^\intercal k(g(X_i), g(X_j)) (e_{Y_j} - g(X_j))$.
      \begin{tcolorbox}[colback=sandstark]
        If $\mathbb{E}[\|k(g(X),g(X))\|] < \infty$, then the following estimators are \hl{consistent estimators of the squared kernel calibration error} $\squaredkernelmeasure[k, g] \coloneqq \kernelmeasure[k,g]^2$.
        \begin{center}
          \begin{tabular}{llll} \toprule
            Notation & Definition & Properties & Complexity\\ \midrule
            $\biasedskce$ & $n^{-2} \sum_{i,j=1}^n h_{i,j}$ & biased & $O(n^2)$ \\
            $\unbiasedskce$ & $ {\binom{n}{2}}^{-1} \sum_{1 \leq i < j \leq n} h_{i,j}$ & unbiased & $O(n^2)$ \\
            $\linearskce$ & $ {\lfloor n/2\rfloor}^{-1} \sum_{i = 1}^{\lfloor n / 2\rfloor} h_{2i-1,2i}$ & unbiased & $O(n)$ \\ \bottomrule
          \end{tabular}
        \end{center}
      \end{tcolorbox}
    \end{itemize}
  }

  \posterbox[adjusted title={Experiments}]{name=experiment,column=4,span=2,between=estimator and footline}{
    We construct data sets $\{g(X_i), Y_i\}_{i=1}^{250}$ of three models with $10$ classes by sampling predictions $g(X_i) \sim \Dir(0.1, \dots, 0.1)$ and labels $Y_i$ conditionally on $g(X_i)$ from
    \begin{align*}
      \text{\textbf{M1: }} &\Categorical(g(X_i)), &
                                                    \text{\textbf{M2: }} &0.5\Categorical(g(X_i)) + 0.5\Categorical(1,0,\dots,0), &
                                                                                                                                    \text{\textbf{M3: }} &\Categorical(0.1, \dots, 0.1).
    \end{align*}
    Model \textbf{M1} is calibrated, and models \textbf{M2} and \textbf{M3} are uncalibrated.

    \begin{center}
      \input{figures/comparison_estimates.tex}
      \captionof{figure}{Calibration error estimates of $10^4$ randomly sampled data sets. The solid black line indicates the mean of the calibration error estimates, and the dashed red line displays the true calibration error of the model.}
    \end{center}

    \begin{center}
      \input{figures/comparison_tests.tex}
      \captionof{figure}{Test errors versus bounds/approximations of the probability of false rejection, evaluated on $500$ ($\asympunbiasedskce$) and $10^4$ (all other test statistics) randomly sampled data sets. For model \textbf{M1} the type I error is shown, for both uncalibrated models the type II error is plotted.}
    \end{center}
  }
\end{tcbposter}
\end{document}
