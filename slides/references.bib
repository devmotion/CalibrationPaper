@InProceedings{guo17_calib_moder_neural_networ,
  author =       {Chuan Guo and Geoff Pleiss and Yu Sun and Kilian
                  Q. Weinberger},
  title =        {On Calibration of Modern Neural Networks},
  booktitle =    {Proceedings of the 34th International Conference on
                  Machine Learning},
  year =         2017,
  volume =       70,
  pages =        {1321--1330},
  url =          {http://proceedings.mlr.press/v70/guo17a.html},
  abstract =     {Confidence calibration - the problem of predicting
                  probability estimates representative of the true
                  correctness likelihood - is important for
                  classification models in many applications. We
                  discover that modern neural networks, unlike those
                  from a decade ago, are poorly calibrated. Through
                  extensive experiments, we observe that depth, width,
                  weight decay, and Batch Normalization are important
                  factors influencing calibration. We evaluate the
                  performance of various post-processing calibration
                  methods on state-of-the-art architectures with image
                  and document classification datasets. Our analysis
                  and experiments not only offer insights into neural
                  network learning, but also provide a simple and
                  straightforward recipe for practical settings: on
                  most datasets, temperature scaling - a
                  single-parameter variant of Platt Scaling - is
                  surprisingly effective at calibrating predictions.},
  month =        08,
  pdf =          {http://proceedings.mlr.press/v70/guo17a/guo17a.pdf},
  series =       {Proceedings of Machine Learning Research},
}

@InProceedings{vaicenavicius19_evaluat,
  author =       {Vaicenavicius, Juozas and Widmann, David and
                  Andersson, Carl and Lindsten, Fredrik and Roll,
                  Jacob and Sch\"{o}n, Thomas B.},
  title =        {Evaluating model calibration in classification},
  booktitle =    {Proceedings of Machine Learning Research},
  year =         2019,
  volume =       89,
  pages =        {3459--3467},
  abstract =     {Probabilistic classifiers output a probability
                  distribution on target classes rather than just a
                  class prediction. Besides providing a clear
                  separation of prediction and decision making, the
                  main advantage of probabilistic models is their
                  ability to represent uncertainty about
                  predictions. In safety-critical applications, it is
                  pivotal for a model to possess an adequate sense of
                  uncertainty, which for probabilistic classifiers
                  translates into outputting probability distributions
                  that are consistent with the empirical frequencies
                  observed from realized outcomes. A classifier with
                  such a property is called calibrated. In this work,
                  we develop a general theoretical calibration
                  evaluation framework grounded in probability theory,
                  and point out subtleties present in model
                  calibration evaluation that lead to refined
                  interpretations of existing evaluation
                  techniques. Lastly, we propose new ways to quantify
                  and visualize miscalibration in probabilistic
                  classification, including novel multidimensional
                  reliability diagrams.},
  month =        4,
  series =       {Proceedings of Machine Learning Research},
}

@article{broecker07_increas_reliab_reliab_diagr,
  author =       {Jochen Br{\"o}cker and Leonard A. Smith},
  title =        {Increasing the Reliability of Reliability Diagrams},
  journal =      {Weather and Forecasting},
  volume =       {22},
  number =       {3},
  pages =        {651-661},
  year =         {2007},
  doi =          {10.1175/waf993.1},
  url =          {https://doi.org/10.1175/waf993.1},
  DATE_ADDED =   {Wed Oct 23 10:41:11 2019},
}
